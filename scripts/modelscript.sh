#Slurm submission header:

#!/bin/bash
#----------------------------------------------------
# Sample Slurm job script
#   for TACC Stampede2 KNL nodes
#
#   *** Serial Job on Normal Queue ***
# 
# Last revised: 20 Oct 2017
#
# Notes:
#
#   -- Copy/edit this script as desired.  Launch by executing
#      "sbatch knl.serial.slurm" on a Stampede2 login node.
#
#   -- Serial codes run on a single node (upper case N = 1).
#        A serial code ignores the value of lower case n,
#        but slurm needs a plausible value to schedule the job.
#
#   -- For a good way to run multiple serial executables at the
#        same time, execute "module load launcher" followed
#        by "module help launcher".

#----------------------------------------------------

#SBATCH -J Job%j           # Job name
#SBATCH -o /scratch/06117/sd34498/data/stdfiles/out.o%j       # Name of stdout output file
#SBATCH -e /scratch/06117/sd34498/data/stdfiles/err.e%j       # Name of stderr error file
#SBATCH -p normal          # Queue (partition) name
#SBATCH -N 1               # Total # of nodes (must be 1 for serial)
#SBATCH -n 1               # Total # of mpi tasks (should be 1 for serial)
#SBATCH -t 12:30:00        # Run time (hh:mm:ss)
#SBATCH --mail-user=*****@utexas.edu
#SBATCH --mail-type=all    # Send email at begin and end of job
# Allocation name (req'd if you have more than 1)

# Other commands must follow all #SBATCH directives...

#End of submission script

#Header of running script which includes modules to be loaded and defining source and input files
#!/bin/bash

module load samtools

SCRATCH=/scratch/06117/sd34498/
WORK=/work/06117/sd34498/stampede2/

source /home1/06117/sd34498/.bashrc

input1= passed as cmd line parameter. Present in an accessible folder in protected location.
input2= passed as cmd line parameter. Present in an accessible folder in protected location.

#End of header file... Begin Base script

#Defining output names and creation of respective directories

output1=$(basename $input1| awk -F "_" '{print($4"_"$5)}')
output2=$(basename $input2| awk -F "_" '{print($4"_"$5)}')

mkdir  $SCRATCH/data/fastqc/${output1}
mkdir  $SCRATCH/data/clippedreads/${output1}
mkdir  $SCRATCH/data/alignment/${output1}
mkdir  $SCRATCH/data/sorted/${output1}
#echo $output1
#echo $output2

#Trimming of reads based on adapter - detected adapter was Truseq, used a generic truseq adapter including all indexes on both read pairs. Trimming also carried out with minimum quality score of 22 and min length 22. Finally 6 bases removed from both starting and ending of reads to assure that base content/position is uniform. Outputs stored in respective output folders in clipped reads folder.
 

cutadapt -a GATCGGAAGAGCACACGTCTGAACTCCAGTCACNNNNNNATCTCGTATGCCGTCTTCTGCTTG -A GATCGGAAGAGCACACGTCTGAACTCCAGTCACNNNNNNATCTCGTATGCCGTCTTCTGCTTG -A CAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTC -u 6 -U 6 -q 22 -m 22 -o $SCRATCH/data/clippedreads/${output1}/clipped_${output1}_R1.fastq.gz -p $SCRATCH/data/clippedreads/${output1}/clipped_${output2}_R2.fastq.gz $input1 $input2 


# Quality check using FastQC, files stored in respective folders in FastQC directory


fastqc -o $SCRATCH/data/fastqc/${output1}/      $SCRATCH/data/clippedreads/${output1}/clipped_${output1}_R1.fastq.gz
fastqc -o $SCRATCH/data/fastqc/${output2}/	$SCRATCH/data/clippedreads/${output1}/clipped_${output2}_R2.fastq.gz


#Alignment of trimmed reads to genome. Used hg38_trans_snp index from ccb-jhu(hisat manual also has info regarding this.) Reads are accessed from clipped reads folder and aligned in paired mode. # of cores to use set at 32.Output file are stored in corresponding folders under alignment directory in sam format. Along with that, information about unaligned files also stored in the same folder. Alignement stats can be accessed thro the standard out/err files generated by the slurm scirpt.   

hisat2 -p 32 -x $indexsnp -1 $SCRATCH/data/clippedreads/${output1}/clipped_${output1}_R1.fastq.gz -2 $SCRATCH/data/clippedreads/${output1}/clipped_${output2}_R2.fastq.gz -S $SCRATCH/data/alignment/${output1}/${output1}_align.sam --un-conc-gz $SCRATCH/data/alignment/${output1}/${output1}_unaligned.gz


#converting sam to bam , sorting and indexing the sorted files. Outputs stored in sorted directory in corresponding folders. Uses 32 cores to perform.

samtools view -@ 32 -bS $SCRATCH/data/alignment/${output1}/${output1}_align.sam |samtools sort -@ 32 -o $SCRATCH/data/sorted/${output1}/${output1}_sorted.bam   
samtools index -@ 32 -b $SCRATCH/data/sorted/${output1}/${output1}_sorted.bam


#Final transcript quantification and generation of expression tables using stringtie. uses 32 cores to perform. Modified Chess anotation file provided. Original Chess anotation files had Chr1 format, replaced here with just 1 (chr1 -> 1,chr22 -> 22 etc) using " perl -pe 's/$1/$2/g' file" command. Here $1 is replaced by $2.Output expression tables are stored in ballgown directory in corresponding folders. We are interested in files named "t_data" and "geneabundance" which has transcript abundance and gene abundance tables. Further analysis can be done using R.
 

stringtie -M 0.75  -e -p 32 -G $WORK/chessmod.gtf -b $SCRATCH/data/ballgown/${output1}/ -A $SCRATCH/data/ballgown/${output1}/gene_abundance.tab $SCRATCH/data/sorted/${output1}/${output1}_sorted.bam -o $SCRATCH/data/misc/${output1}/n.gtf



#After completion of job, alignment stats, cutadapt trimming details can be accessed from corresponding std out and std err files. Be sure to match the right files using job id and adapter name.



